{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b19330-6aee-408e-9cf7-8d604fd0521e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf273ac4-cabe-4031-8d4e-5f1653283a78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/30 00:51:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/30 00:51:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/08/30 00:51:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "/Users/arpit/anaconda3/lib/python3.10/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('fivethirtyeight')\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc=SparkContext()\n",
    "sqlContext=SQLContext(sc)\n",
    "spark=SparkSession(sc)\n",
    "from pyspark.sql.functions import col,split, regexp_extract,to_timestamp,year, month, hour, minute, second,date_format\n",
    "import re #Regular expressions for extracting the features for our project\n",
    "import glob #The glob function in Python allows you to retrieve a list of file paths that match a specified pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565e45d-3bd4-45c7-a1f7-1e27b606c75b",
   "metadata": {},
   "source": [
    "## Reading the Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91d5d50-02be-42b0-8de9-a082bf74acc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b783b27-e8cc-4f0f-8bcb-379fdb4e4d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nginx/access.log-20230215.gz',\n",
       " 'nginx/proxy.log-20230214.gz',\n",
       " 'nginx/proxy.log-20230220.gz',\n",
       " 'nginx/access.log-20230221.gz',\n",
       " 'nginx/error.log-20230220.gz',\n",
       " 'nginx/error.log-20230214.gz',\n",
       " 'nginx/error.log-20230221.gz',\n",
       " 'nginx/error.log-20230215.gz',\n",
       " 'nginx/access.log-20230214.gz',\n",
       " 'nginx/proxy.log-20230215.gz',\n",
       " 'nginx/proxy.log-20230221.gz',\n",
       " 'nginx/access.log-20230220.gz',\n",
       " 'nginx/access.log-20230219.gz',\n",
       " 'nginx/proxy.log-20230218.gz',\n",
       " 'nginx/error.log-20230218.gz',\n",
       " 'nginx/error.log-20230219.gz',\n",
       " 'nginx/access.log-20230218.gz',\n",
       " 'nginx/proxy.log-20230219.gz',\n",
       " 'nginx/error.log-20230222.gz',\n",
       " 'nginx/error.log-20230216.gz',\n",
       " 'nginx/access.log-20230213.gz',\n",
       " 'nginx/proxy.log-20230216.gz',\n",
       " 'nginx/access.log-20230217.gz',\n",
       " 'nginx/proxy.log-20230222.gz',\n",
       " 'nginx/proxy.log-20230217.gz',\n",
       " 'nginx/error.log-20230213.gz',\n",
       " 'nginx/access.log-20230216.gz',\n",
       " 'nginx/access.log-20230222.gz',\n",
       " 'nginx/error.log-20230217.gz',\n",
       " 'nginx/proxy.log-20230213.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_folder = \"nginx\"  # \"log\" folder contains all the log data thus giving its path\n",
    "#Glob is commonly used to search for files and directories in a directory structure based on specific criteria.\n",
    "raw_data_files=glob.glob(\"nginx/*.gz\") #(glob Stands for 'Global')\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3de098-7018-4f0d-96bc-e65b6b1c099b",
   "metadata": {},
   "source": [
    "## Printing the scema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861d99e0-08ff-4fd7-b050-177168c572c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df1=spark.read.text(raw_data_files)\n",
    "log_df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e048104-addc-41a1-b839-a0f87924c8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                                                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|143.244.50.172 - - [16/Feb/2023:03:28:45 +0530] \"GET /config/getuser?index=0 HTTP/1.1\" 400 248 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0\"                                                                                                                                            |\n",
      "|164.90.235.116 - - [16/Feb/2023:04:11:34 +0530] \"GET / HTTP/1.1\" 200 5952 \"http://14.139.152.12/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"                                                                                                          |\n",
      "|66.249.69.126 - - [16/Feb/2023:04:39:52 +0530] \"GET /robots.txt HTTP/1.1\" 404 146 \"-\" \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\"                                                                                                                                                             |\n",
      "|66.249.69.126 - - [16/Feb/2023:04:39:52 +0530] \"GET /assets/img/favicon.png HTTP/1.1\" 200 491 \"-\" \"Googlebot-Image/1.0\"                                                                                                                                                                                                      |\n",
      "|185.221.219.172 - - [16/Feb/2023:05:06:47 +0530] \"GET /.git/config HTTP/1.1\" 404 548 \"-\" \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.2; Trident/5.0)\"                                                                                                                                                                   |\n",
      "|66.249.69.101 - - [16/Feb/2023:05:24:52 +0530] \"GET /apim/devportal/site/public/images/logo.svg HTTP/1.1\" 304 0 \"-\" \"Googlebot-Image/1.0\"                                                                                                                                                                                    |\n",
      "|52.167.144.90 - - [16/Feb/2023:06:26:16 +0530] \"GET / HTTP/1.1\" 200 5952 \"-\" \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm) Chrome/103.0.5060.134 Safari/537.36\"                                                                                             |\n",
      "|152.89.196.211 - - [16/Feb/2023:07:00:15 +0530] \"GET /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php HTTP/1.1\" 404 548 \"http://14.139.152.12:80/vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\"|\n",
      "|114.119.133.53 - - [16/Feb/2023:07:01:52 +0530] \"GET /robots.txt HTTP/1.1\" 404 146 \"-\" \"Mozilla/5.0 (compatible;PetalBot;+https://webmaster.petalsearch.com/site/petalbot)\"                                                                                                                                                  |\n",
      "|198.20.69.98 - - [16/Feb/2023:07:26:00 +0530] \"GET / HTTP/1.1\" 200 5952 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/30 01:58:33 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1004697 ms exceeds timeout 120000 ms\n",
      "23/08/30 01:58:34 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/08/30 01:58:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:58:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:58:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:58:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:58:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:58:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:59:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:59:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:59:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:59:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 01:59:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 01:59:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:00:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:01:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:01:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:01:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:02:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:02:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:02:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:03:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:04:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:05:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:05:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:06:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:06:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:07:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:07:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:07:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:07:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:14:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:14:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:14:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:14:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:14:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:14:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:15:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:15:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:15:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:15:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/08/30 02:15:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:15:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:22:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:22:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.104.124.18:59764\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/08/30 02:22:45 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "log_df1.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488ce0f-c60a-48a9-83d6-cbc390e3d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 198.20.69.98 - - [16/Feb/2023:07:26:00 +0530] \"GET / HTTP/1.1\" 2001 15952 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b75f8b8-2ae3-4c88-a87b-80081e0ded1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ip_address='143.244.50.172', HTTP request line='GET', user_agent='/config/getuser?index=0', protocol='HTTP/1.1', HTTP status code='143', Size of the response in bytes='248', response_time=0, year='2023', month='Feb', date='16', hour='03', minute='28', seconds='45'),\n",
       " Row(Ip_address='164.90.235.116', HTTP request line='GET', user_agent='/', protocol='HTTP/1.1', HTTP status code='164', Size of the response in bytes='5952', response_time=0, year='2023', month='Feb', date='16', hour='04', minute='11', seconds='34'),\n",
       " Row(Ip_address='66.249.69.126', HTTP request line='GET', user_agent='/robots.txt', protocol='HTTP/1.1', HTTP status code='249', Size of the response in bytes='146', response_time=0, year='2023', month='Feb', date='16', hour='04', minute='39', seconds='52'),\n",
       " Row(Ip_address='66.249.69.126', HTTP request line='GET', user_agent='/assets/img/favicon.png', protocol='HTTP/1.1', HTTP status code='249', Size of the response in bytes='491', response_time=0, year='2023', month='Feb', date='16', hour='04', minute='39', seconds='52'),\n",
       " Row(Ip_address='185.221.219.172', HTTP request line='GET', user_agent='/.git/config', protocol='HTTP/1.1', HTTP status code='185', Size of the response in bytes='548', response_time=0, year='2023', month='Feb', date='16', hour='05', minute='06', seconds='47')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59fab7-19d9-4bf0-b775-00d0ed6a35ba",
   "metadata": {},
   "source": [
    "## Using RE for Extracting the features of log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4068da11-8bb8-4131-9355-f0753af2cc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ip_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "timestamp_pattern = r'\\[(\\d{2}/\\w+/\\d{4}:\\d{2}:\\d{2}:\\d{2} \\+\\d{4})\\]'\n",
    "request_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n",
    "status_pattern = r'(\\d{3})'\n",
    "size_pattern = r'\\s(\\d+) \"'\n",
    "user_agent_pattern = r'\"([^\"]+)\"'\n",
    "protocol_pattern = r'HTTP/([\\d.]+)'\n",
    "browser_pattern = r'\"([^\"]+)\"$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fc0a33-e1c1-4431-8ec9-233c63aa78e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_df1 = log_df1.select(\n",
    "                         regexp_extract(col(\"value\"), ip_pattern, 1).alias(\"Ip_address\"),\n",
    "                         regexp_extract(col(\"value\"), timestamp_pattern, 1).alias(\"timestamp\"),\n",
    "                         regexp_extract(col(\"value\"), request_pattern, 1).alias(\"HTTP request line\"),\n",
    "                         regexp_extract(col(\"value\"), request_pattern, 2).alias(\"user_agent\"),\n",
    "                         regexp_extract(col(\"value\"), request_pattern, 3).alias(\"protocol\"),\n",
    "                         regexp_extract(col(\"value\"), status_pattern, 1).alias(\"HTTP status code\"),\n",
    "                         regexp_extract(col(\"value\"), size_pattern, 1).alias(\"Size of the response in bytes\"),\n",
    "                        )\n",
    "log_df1 = log_df1.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"dd/MMM/yyyy:HH:mm:ss Z\"))\n",
    "log_df1 = log_df1.withColumn(\"response_time\", (col(\"timestamp\").cast(\"long\") - col(\"timestamp\").cast(\"long\")).cast(\"int\"))\n",
    "\n",
    "log_df1 = log_df1.withColumn(\"year\", col(\"timestamp\").substr(1, 4))\n",
    "log_df1 = log_df1.withColumn(\"month\", date_format(col(\"timestamp\"), \"MMM\"))\n",
    "log_df1 = log_df1.withColumn(\"date\", col(\"timestamp\").substr(9, 2))\n",
    "log_df1 = log_df1.withColumn(\"hour\", col(\"timestamp\").substr(12, 2))\n",
    "log_df1 = log_df1.withColumn(\"minute\", col(\"timestamp\").substr(15, 2))\n",
    "log_df1 = log_df1.withColumn(\"seconds\", col(\"timestamp\").substr(18, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65ec37f-849d-4417-b0c4-5ca1123d4cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_df1 = log_df1.drop(\"timestamp\")\n",
    "## Droping the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0d2c47-52a2-498e-880f-2fb8cea42497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.244.50.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/config/getuser?index=0</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.90.235.116</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/robots.txt</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/assets/img/favicon.png</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185.221.219.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/.git/config</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td></td>\n",
       "      <td>GET</td>\n",
       "      <td>/sitemaps.xml</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>202</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td></td>\n",
       "      <td>GET</td>\n",
       "      <td>/robots.txt</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>202</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td></td>\n",
       "      <td>GET</td>\n",
       "      <td>/favicon.ico</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>202</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td></td>\n",
       "      <td>GET</td>\n",
       "      <td>/owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>202</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td></td>\n",
       "      <td>GET</td>\n",
       "      <td>/wp-login.php</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>202</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6218 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ip_address HTTP request line  \\\n",
       "0      143.244.50.172               GET   \n",
       "1      164.90.235.116               GET   \n",
       "2       66.249.69.126               GET   \n",
       "3       66.249.69.126               GET   \n",
       "4     185.221.219.172               GET   \n",
       "...               ...               ...   \n",
       "6213                                GET   \n",
       "6214                                GET   \n",
       "6215                                GET   \n",
       "6216                                GET   \n",
       "6217                                GET   \n",
       "\n",
       "                                             user_agent  protocol  \\\n",
       "0                               /config/getuser?index=0  HTTP/1.1   \n",
       "1                                                     /  HTTP/1.1   \n",
       "2                                           /robots.txt  HTTP/1.1   \n",
       "3                               /assets/img/favicon.png  HTTP/1.1   \n",
       "4                                          /.git/config  HTTP/1.1   \n",
       "...                                                 ...       ...   \n",
       "6213                                      /sitemaps.xml  HTTP/1.1   \n",
       "6214                                        /robots.txt  HTTP/1.1   \n",
       "6215                                       /favicon.ico  HTTP/1.1   \n",
       "6216  /owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f  HTTP/1.1   \n",
       "6217                                      /wp-login.php  HTTP/1.1   \n",
       "\n",
       "     HTTP status code Size of the response in bytes  response_time  year  \\\n",
       "0                 143                           248            0.0  2023   \n",
       "1                 164                          5952            0.0  2023   \n",
       "2                 249                           146            0.0  2023   \n",
       "3                 249                           491            0.0  2023   \n",
       "4                 185                           548            0.0  2023   \n",
       "...               ...                           ...            ...   ...   \n",
       "6213              202                                          NaN  None   \n",
       "6214              202                                          NaN  None   \n",
       "6215              202                                          NaN  None   \n",
       "6216              202                                          NaN  None   \n",
       "6217              202                                          NaN  None   \n",
       "\n",
       "     month  date  hour minute seconds  \n",
       "0      Feb    16    03     28      45  \n",
       "1      Feb    16    04     11      34  \n",
       "2      Feb    16    04     39      52  \n",
       "3      Feb    16    04     39      52  \n",
       "4      Feb    16    05     06      47  \n",
       "...    ...   ...   ...    ...     ...  \n",
       "6213  None  None  None   None    None  \n",
       "6214  None  None  None   None    None  \n",
       "6215  None  None  None   None    None  \n",
       "6216  None  None  None   None    None  \n",
       "6217  None  None  None   None    None  \n",
       "\n",
       "[6218 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pandas_df = log_df1.toPandas() #Converting it into Pandas dataframe for better visualization\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14aee15-754a-4126-9c16-c5dc0a0d0ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.244.50.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/config/getuser?index=0</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.90.235.116</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/robots.txt</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/assets/img/favicon.png</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185.221.219.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/.git/config</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>GET</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>188.165.87.111</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>188</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ip_address HTTP request line               user_agent  protocol  \\\n",
       "0      143.244.50.172               GET  /config/getuser?index=0  HTTP/1.1   \n",
       "1      164.90.235.116               GET                        /  HTTP/1.1   \n",
       "2       66.249.69.126               GET              /robots.txt  HTTP/1.1   \n",
       "3       66.249.69.126               GET  /assets/img/favicon.png  HTTP/1.1   \n",
       "4     185.221.219.172               GET             /.git/config  HTTP/1.1   \n",
       "...               ...               ...                      ...       ...   \n",
       "5731   154.12.227.174              POST               /core/.env  HTTP/1.1   \n",
       "5732   154.12.227.174               GET               /core/.env  HTTP/1.1   \n",
       "5733   154.12.227.174              POST                        /  HTTP/1.1   \n",
       "5734   154.12.227.174              POST               /core/.env  HTTP/1.1   \n",
       "5735   188.165.87.111               GET                        /  HTTP/1.1   \n",
       "\n",
       "     HTTP status code Size of the response in bytes  response_time  year  \\\n",
       "0                 143                           248            0.0  2023   \n",
       "1                 164                          5952            0.0  2023   \n",
       "2                 249                           146            0.0  2023   \n",
       "3                 249                           491            0.0  2023   \n",
       "4                 185                           548            0.0  2023   \n",
       "...               ...                           ...            ...   ...   \n",
       "5731              154                           146            0.0  2023   \n",
       "5732              154                           146            0.0  2023   \n",
       "5733              154                           150            0.0  2023   \n",
       "5734              154                           146            0.0  2023   \n",
       "5735              188                          5952            0.0  2023   \n",
       "\n",
       "     month date hour minute seconds  \n",
       "0      Feb   16   03     28      45  \n",
       "1      Feb   16   04     11      34  \n",
       "2      Feb   16   04     39      52  \n",
       "3      Feb   16   04     39      52  \n",
       "4      Feb   16   05     06      47  \n",
       "...    ...  ...  ...    ...     ...  \n",
       "5731   Feb   19   02     48      08  \n",
       "5732   Feb   19   02     48      10  \n",
       "5733   Feb   19   02     48      12  \n",
       "5734   Feb   19   02     48      13  \n",
       "5735   Feb   19   03     06      29  \n",
       "\n",
       "[5736 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pandas_df=log_pandas_df.dropna()\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab1111-90a6-46f0-a96f-fafc13cb7062",
   "metadata": {},
   "source": [
    "## Checking the Null Values in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75058525-4001-476d-8b90-8caad9f7aba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ip_address                       0\n",
       "HTTP request line                0\n",
       "user_agent                       0\n",
       "protocol                         0\n",
       "HTTP status code                 0\n",
       "Size of the response in bytes    0\n",
       "response_time                    0\n",
       "year                             0\n",
       "month                            0\n",
       "date                             0\n",
       "hour                             0\n",
       "minute                           0\n",
       "seconds                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pandas_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d3bc4-5bb0-4cb1-aadb-043086a9af5b",
   "metadata": {},
   "source": [
    "## Addition of 'Total no of requests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f262c3-44e7-4111-8690-4b89bca45b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/2344694714.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['No of Requests']=log_pandas_df.groupby(['Ip_address'])['user_agent'].transform('count')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>No of Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143.244.50.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/config/getuser?index=0</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.90.235.116</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/robots.txt</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.249.69.126</td>\n",
       "      <td>GET</td>\n",
       "      <td>/assets/img/favicon.png</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185.221.219.172</td>\n",
       "      <td>GET</td>\n",
       "      <td>/.git/config</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>GET</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>154.12.227.174</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>188.165.87.111</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>188</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ip_address HTTP request line               user_agent  protocol  \\\n",
       "0      143.244.50.172               GET  /config/getuser?index=0  HTTP/1.1   \n",
       "1      164.90.235.116               GET                        /  HTTP/1.1   \n",
       "2       66.249.69.126               GET              /robots.txt  HTTP/1.1   \n",
       "3       66.249.69.126               GET  /assets/img/favicon.png  HTTP/1.1   \n",
       "4     185.221.219.172               GET             /.git/config  HTTP/1.1   \n",
       "...               ...               ...                      ...       ...   \n",
       "5731   154.12.227.174              POST               /core/.env  HTTP/1.1   \n",
       "5732   154.12.227.174               GET               /core/.env  HTTP/1.1   \n",
       "5733   154.12.227.174              POST                        /  HTTP/1.1   \n",
       "5734   154.12.227.174              POST               /core/.env  HTTP/1.1   \n",
       "5735   188.165.87.111               GET                        /  HTTP/1.1   \n",
       "\n",
       "     HTTP status code Size of the response in bytes  response_time  year  \\\n",
       "0                 143                           248            0.0  2023   \n",
       "1                 164                          5952            0.0  2023   \n",
       "2                 249                           146            0.0  2023   \n",
       "3                 249                           491            0.0  2023   \n",
       "4                 185                           548            0.0  2023   \n",
       "...               ...                           ...            ...   ...   \n",
       "5731              154                           146            0.0  2023   \n",
       "5732              154                           146            0.0  2023   \n",
       "5733              154                           150            0.0  2023   \n",
       "5734              154                           146            0.0  2023   \n",
       "5735              188                          5952            0.0  2023   \n",
       "\n",
       "     month date hour minute seconds  No of Requests  \n",
       "0      Feb   16   03     28      45              62  \n",
       "1      Feb   16   04     11      34               5  \n",
       "2      Feb   16   04     39      52              20  \n",
       "3      Feb   16   04     39      52              20  \n",
       "4      Feb   16   05     06      47               1  \n",
       "...    ...  ...  ...    ...     ...             ...  \n",
       "5731   Feb   19   02     48      08               6  \n",
       "5732   Feb   19   02     48      10               6  \n",
       "5733   Feb   19   02     48      12               6  \n",
       "5734   Feb   19   02     48      13               6  \n",
       "5735   Feb   19   03     06      29               1  \n",
       "\n",
       "[5736 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pandas_df['No of Requests']=log_pandas_df.groupby(['Ip_address'])['user_agent'].transform('count')\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12f747-bf0f-4ea7-984b-1ae1e6cfc7ad",
   "metadata": {},
   "source": [
    "## Encoding IPaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6a30ef7-917c-45be-bf33-e2e0883b7ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/2713326293.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['Ip_address'] = log_pandas_df['Ip_address'].apply(convert_ip_to_numeric)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>No of Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2415145644</td>\n",
       "      <td>GET</td>\n",
       "      <td>/config/getuser?index=0</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2757421940</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>GET</td>\n",
       "      <td>/robots.txt</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>GET</td>\n",
       "      <td>/assets/img/favicon.png</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3118324652</td>\n",
       "      <td>GET</td>\n",
       "      <td>/.git/config</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>GET</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>POST</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>POST</td>\n",
       "      <td>/core/.env</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>3164952431</td>\n",
       "      <td>GET</td>\n",
       "      <td>/</td>\n",
       "      <td>HTTP/1.1</td>\n",
       "      <td>188</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Feb</td>\n",
       "      <td>19</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ip_address HTTP request line               user_agent  protocol  \\\n",
       "0     2415145644               GET  /config/getuser?index=0  HTTP/1.1   \n",
       "1     2757421940               GET                        /  HTTP/1.1   \n",
       "2     1123632510               GET              /robots.txt  HTTP/1.1   \n",
       "3     1123632510               GET  /assets/img/favicon.png  HTTP/1.1   \n",
       "4     3118324652               GET             /.git/config  HTTP/1.1   \n",
       "...          ...               ...                      ...       ...   \n",
       "5731  2584535982              POST               /core/.env  HTTP/1.1   \n",
       "5732  2584535982               GET               /core/.env  HTTP/1.1   \n",
       "5733  2584535982              POST                        /  HTTP/1.1   \n",
       "5734  2584535982              POST               /core/.env  HTTP/1.1   \n",
       "5735  3164952431               GET                        /  HTTP/1.1   \n",
       "\n",
       "     HTTP status code Size of the response in bytes  response_time  year  \\\n",
       "0                 143                           248            0.0  2023   \n",
       "1                 164                          5952            0.0  2023   \n",
       "2                 249                           146            0.0  2023   \n",
       "3                 249                           491            0.0  2023   \n",
       "4                 185                           548            0.0  2023   \n",
       "...               ...                           ...            ...   ...   \n",
       "5731              154                           146            0.0  2023   \n",
       "5732              154                           146            0.0  2023   \n",
       "5733              154                           150            0.0  2023   \n",
       "5734              154                           146            0.0  2023   \n",
       "5735              188                          5952            0.0  2023   \n",
       "\n",
       "     month date hour minute seconds  No of Requests  \n",
       "0      Feb   16   03     28      45              62  \n",
       "1      Feb   16   04     11      34               5  \n",
       "2      Feb   16   04     39      52              20  \n",
       "3      Feb   16   04     39      52              20  \n",
       "4      Feb   16   05     06      47               1  \n",
       "...    ...  ...  ...    ...     ...             ...  \n",
       "5731   Feb   19   02     48      08               6  \n",
       "5732   Feb   19   02     48      10               6  \n",
       "5733   Feb   19   02     48      12               6  \n",
       "5734   Feb   19   02     48      13               6  \n",
       "5735   Feb   19   03     06      29               1  \n",
       "\n",
       "[5736 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert IP address to numerical value\n",
    "import ipaddress\n",
    "def convert_ip_to_numeric(ip_str):\n",
    "    ip = ipaddress.ip_address(ip_str)\n",
    "    return int(ip)\n",
    "    \n",
    "\n",
    "# Apply the conversion function to the entire column\n",
    "log_pandas_df['Ip_address'] = log_pandas_df['Ip_address'].apply(convert_ip_to_numeric)\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b21091-13a4-4ff9-8919-be3ca3c3fd55",
   "metadata": {},
   "source": [
    "## Encoding Other Categorical Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b7dc7c-c062-467d-b3c3-1334be1e9e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/1393602270.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['HTTP request line'] = label_encoder.fit_transform(log_pandas_df['HTTP request line'])\n",
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/1393602270.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['protocol'] = label_encoder.fit_transform(log_pandas_df['protocol'])\n",
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/1393602270.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['user_agent'] = label_encoder.fit_transform(log_pandas_df['protocol'])\n",
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/1393602270.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['month'] = label_encoder.fit_transform(log_pandas_df['month'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>No of Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2415145644</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2757421940</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3118324652</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>3164952431</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ip_address  HTTP request line  user_agent  protocol HTTP status code  \\\n",
       "0     2415145644                  4           6         6              143   \n",
       "1     2757421940                  4           6         6              164   \n",
       "2     1123632510                  4           6         6              249   \n",
       "3     1123632510                  4           6         6              249   \n",
       "4     3118324652                  4           6         6              185   \n",
       "...          ...                ...         ...       ...              ...   \n",
       "5731  2584535982                  7           6         6              154   \n",
       "5732  2584535982                  4           6         6              154   \n",
       "5733  2584535982                  7           6         6              154   \n",
       "5734  2584535982                  7           6         6              154   \n",
       "5735  3164952431                  4           6         6              188   \n",
       "\n",
       "     Size of the response in bytes  response_time  year  month date hour  \\\n",
       "0                              248            0.0  2023      0   16   03   \n",
       "1                             5952            0.0  2023      0   16   04   \n",
       "2                              146            0.0  2023      0   16   04   \n",
       "3                              491            0.0  2023      0   16   04   \n",
       "4                              548            0.0  2023      0   16   05   \n",
       "...                            ...            ...   ...    ...  ...  ...   \n",
       "5731                           146            0.0  2023      0   19   02   \n",
       "5732                           146            0.0  2023      0   19   02   \n",
       "5733                           150            0.0  2023      0   19   02   \n",
       "5734                           146            0.0  2023      0   19   02   \n",
       "5735                          5952            0.0  2023      0   19   03   \n",
       "\n",
       "     minute seconds  No of Requests  \n",
       "0        28      45              62  \n",
       "1        11      34               5  \n",
       "2        39      52              20  \n",
       "3        39      52              20  \n",
       "4        06      47               1  \n",
       "...     ...     ...             ...  \n",
       "5731     48      08               6  \n",
       "5732     48      10               6  \n",
       "5733     48      12               6  \n",
       "5734     48      13               6  \n",
       "5735     06      29               1  \n",
       "\n",
       "[5736 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Apply Label Encoding to the required column\n",
    "label_encoder=LabelEncoder()\n",
    "log_pandas_df['HTTP request line'] = label_encoder.fit_transform(log_pandas_df['HTTP request line'])\n",
    "log_pandas_df['protocol'] = label_encoder.fit_transform(log_pandas_df['protocol'])\n",
    "log_pandas_df['user_agent'] = label_encoder.fit_transform(log_pandas_df['protocol'])\n",
    "log_pandas_df['month'] = label_encoder.fit_transform(log_pandas_df['month'])\n",
    "\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170c779-6af5-4ef3-83c2-7bf44e6c36bf",
   "metadata": {},
   "source": [
    "## Distribution of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a3c4382-4eaf-4816-972c-9f6a1d6215f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "numerical_columns = log_pandas_df.select_dtypes(include=[np.number])\n",
    "\n",
    "for column in numerical_columns.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(log_pandas_df[column], kde=True, color='blue')\n",
    "    \n",
    "    plt.title(f\"Distribution Curve of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Density\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a86f9-6e69-4850-baf2-6b08a6bbb6fe",
   "metadata": {},
   "source": [
    "## DBSCAN Clusturing for finding Anomaly and Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d31dbb-cfd9-46e9-9628-bf671a2d1a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Silhouette Score: 0.133\n",
      "Best eps: 0.5\n",
      "Best min_samples: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(log_pandas_df)\n",
    "\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_score = -1\n",
    "\n",
    "for eps in np.arange(0.5,1.5): \n",
    "    for min_samples in range(2, 10): \n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(normalized_data)\n",
    "        \n",
    "        if len(set(labels)) > 1:  \n",
    "            score = silhouette_score(normalized_data, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "\n",
    "print(f\"Best Silhouette Score: {best_score:.3f}\")\n",
    "print(f\"Best eps: {best_eps}\")\n",
    "print(f\"Best min_samples: {best_min_samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b323f95-cb4d-4440-9552-568f1e38885e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the k-distance graph\n",
    "k_distance = 2\n",
    "neigh = NearestNeighbors(n_neighbors=k_distance)\n",
    "neigh.fit(normalized_data)\n",
    "distances, _ = neigh.kneighbors()\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.plot(distances[:, -1])\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(f\"{k_distance}-Distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a146622-1ffe-4e34-9e61-20c6a3db2bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 661\n",
      "Distribution of clusters:\n",
      "-1      1876\n",
      " 323     547\n",
      " 484     127\n",
      " 19       82\n",
      " 105      75\n",
      "        ... \n",
      " 263       2\n",
      " 262       2\n",
      " 261       2\n",
      " 260       2\n",
      " 330       2\n",
      "Name: Cluster, Length: 662, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/459717764.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['Cluster'] = labels\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "\n",
    "# Create a subset DataFrame with selected columns\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(data_subset)\n",
    "\n",
    "# Instantiate and fit DBSCAN model\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)  # You can adjust eps and min_samples according to your data\n",
    "labels = dbscan.fit_predict(normalized_data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "log_pandas_df['Cluster'] = labels\n",
    "\n",
    "# Print the number of clusters (excluding noise)\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"Number of clusters: {num_clusters}\")\n",
    "\n",
    "# If you want to see the distribution of clusters\n",
    "print(\"Distribution of clusters:\")\n",
    "print(log_pandas_df['Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d97b49b-295e-4108-ae73-f27e2efdb4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies: 1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/574887272.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['Cluster'] = labels\n",
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/574887272.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['IsAnomaly'] = (log_pandas_df['Cluster'] == -1).astype(int)\n",
      "/var/folders/rs/sxmf7m5s52s2h51r_1p5nwgh0000gn/T/ipykernel_23473/574887272.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log_pandas_df['Anomaly'] = np.where(log_pandas_df['IsAnomaly'] == 1, 'Anomaly', 'Not Anomaly')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ip_address</th>\n",
       "      <th>HTTP request line</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>protocol</th>\n",
       "      <th>HTTP status code</th>\n",
       "      <th>Size of the response in bytes</th>\n",
       "      <th>response_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>seconds</th>\n",
       "      <th>No of Requests</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>IsAnomaly</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2415145644</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>143</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>03</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2757421940</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123632510</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3118324652</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>185</td>\n",
       "      <td>548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>2584535982</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>02</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>3164952431</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>5952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ip_address  HTTP request line  user_agent  protocol HTTP status code  \\\n",
       "0     2415145644                  4           6         6              143   \n",
       "1     2757421940                  4           6         6              164   \n",
       "2     1123632510                  4           6         6              249   \n",
       "3     1123632510                  4           6         6              249   \n",
       "4     3118324652                  4           6         6              185   \n",
       "...          ...                ...         ...       ...              ...   \n",
       "5731  2584535982                  7           6         6              154   \n",
       "5732  2584535982                  4           6         6              154   \n",
       "5733  2584535982                  7           6         6              154   \n",
       "5734  2584535982                  7           6         6              154   \n",
       "5735  3164952431                  4           6         6              188   \n",
       "\n",
       "     Size of the response in bytes  response_time  year  month date hour  \\\n",
       "0                              248            0.0  2023      0   16   03   \n",
       "1                             5952            0.0  2023      0   16   04   \n",
       "2                              146            0.0  2023      0   16   04   \n",
       "3                              491            0.0  2023      0   16   04   \n",
       "4                              548            0.0  2023      0   16   05   \n",
       "...                            ...            ...   ...    ...  ...  ...   \n",
       "5731                           146            0.0  2023      0   19   02   \n",
       "5732                           146            0.0  2023      0   19   02   \n",
       "5733                           150            0.0  2023      0   19   02   \n",
       "5734                           146            0.0  2023      0   19   02   \n",
       "5735                          5952            0.0  2023      0   19   03   \n",
       "\n",
       "     minute seconds  No of Requests  Cluster  IsAnomaly      Anomaly  \n",
       "0        28      45              62        0          0  Not Anomaly  \n",
       "1        11      34               5        1          0  Not Anomaly  \n",
       "2        39      52              20        2          0  Not Anomaly  \n",
       "3        39      52              20        2          0  Not Anomaly  \n",
       "4        06      47               1        3          0  Not Anomaly  \n",
       "...     ...     ...             ...      ...        ...          ...  \n",
       "5731     48      08               6      660          0  Not Anomaly  \n",
       "5732     48      10               6      659          0  Not Anomaly  \n",
       "5733     48      12               6      660          0  Not Anomaly  \n",
       "5734     48      13               6      660          0  Not Anomaly  \n",
       "5735     06      29               1       -1          1      Anomaly  \n",
       "\n",
       "[5736 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "\n",
    "# Create a subset DataFrame with selected columns\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(data_subset)\n",
    "\n",
    "# Instantiate and fit DBSCAN model\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)  \n",
    "labels = dbscan.fit_predict(normalized_data)\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "log_pandas_df['Cluster'] = labels\n",
    "\n",
    "# Create 'IsAnomaly' column based on cluster labels\n",
    "log_pandas_df['IsAnomaly'] = (log_pandas_df['Cluster'] == -1).astype(int)\n",
    "\n",
    "# Add 'Anomaly' column based on 'IsAnomaly'\n",
    "log_pandas_df['Anomaly'] = np.where(log_pandas_df['IsAnomaly'] == 1, 'Anomaly', 'Not Anomaly')\n",
    "\n",
    "# Print the number of anomalies\n",
    "num_anomalies = log_pandas_df['IsAnomaly'].sum()\n",
    "print(f\"Number of anomalies: {num_anomalies}\")\n",
    "\n",
    "# Display the DataFrame with the 'Anomaly' column\n",
    "log_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfb36a-6e6e-401f-90c1-42dcb31fa613",
   "metadata": {},
   "source": [
    "## Save dataframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8944d344-4dd1-4e69-b5e3-6c56bc19fb26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_pandas_df.to_csv('Anomaly1.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c1abc-d502-48c8-ba1d-2f004f92b167",
   "metadata": {},
   "source": [
    "## Use PyOD for Checking Label Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc674c2f-3e3c-45d6-8b38-d7882d42987c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1eaf00a-3f8d-4712-ad13-860a34f5470e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for K-Nearest Neighbors (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      3860\n",
      "           1       0.76      0.20      0.31      1876\n",
      "\n",
      "    accuracy                           0.72      5736\n",
      "   macro avg       0.74      0.58      0.57      5736\n",
      "weighted avg       0.73      0.72      0.65      5736\n",
      "\n",
      "\n",
      "Classification Report for Isolation Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81      3860\n",
      "           1       0.63      0.19      0.29      1876\n",
      "\n",
      "    accuracy                           0.70      5736\n",
      "   macro avg       0.67      0.57      0.55      5736\n",
      "weighted avg       0.68      0.70      0.64      5736\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "algorithms = [\n",
    "    ('K-Nearest Neighbors (KNN)', KNN()),\n",
    "    ('Isolation Forest', IForest())\n",
    "   \n",
    "]\n",
    "\n",
    "for name, model in algorithms:\n",
    "   \n",
    "    model.fit(normalized_data)\n",
    "\n",
    "    # Predict anomalies using the trained model\n",
    "    predicted_labels = model.predict(normalized_data)\n",
    "\n",
    "    # Generate a classification report\n",
    "    classification_rep = classification_report(log_pandas_df['IsAnomaly'], predicted_labels)\n",
    "\n",
    "    print(f\"Classification Report for {name}:\\n{classification_rep}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d2bfd-8cf4-42ab-81e1-952b0a927663",
   "metadata": {},
   "source": [
    "## Now Checking Evaluating the data using Different Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d821c-1d4b-4d8e-9279-9f6a1289cd67",
   "metadata": {},
   "source": [
    "## With OverSampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0785f0e-b44b-4114-ba8d-16d20a8caadc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest...\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       780\n",
      "           1       0.83      0.88      0.85       368\n",
      "\n",
      "    accuracy                           0.90      1148\n",
      "   macro avg       0.88      0.90      0.89      1148\n",
      "weighted avg       0.90      0.90      0.90      1148\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[714  66]\n",
      " [ 46 322]]\n",
      "MCC Score for Random Forest: 0.7798068215867826\n",
      "\n",
      "Fitting XGBoost...\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       780\n",
      "           1       0.85      0.85      0.85       368\n",
      "\n",
      "    accuracy                           0.90      1148\n",
      "   macro avg       0.89      0.89      0.89      1148\n",
      "weighted avg       0.90      0.90      0.90      1148\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      "[[723  57]\n",
      " [ 54 314]]\n",
      "MCC Score for XGBoost: 0.7785217608397688\n",
      "\n",
      "Fitting Support Vector Machine...\n",
      "Classification Report for Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79       780\n",
      "           1       0.57      0.84      0.68       368\n",
      "\n",
      "    accuracy                           0.75      1148\n",
      "   macro avg       0.74      0.77      0.74      1148\n",
      "weighted avg       0.80      0.75      0.76      1148\n",
      "\n",
      "Confusion Matrix for Support Vector Machine:\n",
      "[[551 229]\n",
      " [ 60 308]]\n",
      "MCC Score for Support Vector Machine: 0.5082256084947888\n",
      "\n",
      "Fitting Logistic Regression...\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       780\n",
      "           1       0.49      0.77      0.60       368\n",
      "\n",
      "    accuracy                           0.67      1148\n",
      "   macro avg       0.67      0.70      0.66      1148\n",
      "weighted avg       0.74      0.67      0.68      1148\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[489 291]\n",
      " [ 84 284]]\n",
      "MCC Score for Logistic Regression: 0.37210460478101093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled1, y_train_resampled1 = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Models to evaluate\n",
    "algorithms = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42)),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "  \n",
    "]\n",
    "\n",
    "for name, model in algorithms:\n",
    "    print(f\"Fitting {name}...\")\n",
    "    # Fit the model to the resampled training data\n",
    "    model.fit(X_train_resampled1, y_train_resampled1)\n",
    "\n",
    "    # Predict anomaly labels on the scaled test data\n",
    "    predicted_labels = model.predict(X_test_scaled)\n",
    "\n",
    "    # Generate a classification report\n",
    "    classification_rep = classification_report(y_test, predicted_labels)\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    \n",
    "    mcc = matthews_corrcoef(y_test, predicted_labels)\n",
    "\n",
    "    print(f\"Classification Report for {name}:\\n{classification_rep}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{conf_matrix}\")\n",
    "    print(f\"MCC Score for {name}: {mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155fa7c-ec8d-490b-8704-b71effbc5a64",
   "metadata": {},
   "source": [
    "## Using Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f33ad22a-938a-4467-ba22-da49699481a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest...\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       780\n",
      "           1       0.74      0.92      0.82       368\n",
      "\n",
      "    accuracy                           0.87      1148\n",
      "   macro avg       0.85      0.88      0.86      1148\n",
      "weighted avg       0.89      0.87      0.87      1148\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[659 121]\n",
      " [ 29 339]]\n",
      "MCC Score for Random Forest: 0.7295668355423666\n",
      "\n",
      "Fitting XGBoost...\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       780\n",
      "           1       0.76      0.89      0.82       368\n",
      "\n",
      "    accuracy                           0.87      1148\n",
      "   macro avg       0.85      0.88      0.86      1148\n",
      "weighted avg       0.88      0.87      0.88      1148\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      "[[674 106]\n",
      " [ 39 329]]\n",
      "MCC Score for XGBoost: 0.7293269071566372\n",
      "\n",
      "Fitting Support Vector Machine...\n",
      "Classification Report for Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.81       780\n",
      "           1       0.59      0.84      0.69       368\n",
      "\n",
      "    accuracy                           0.76      1148\n",
      "   macro avg       0.75      0.78      0.75      1148\n",
      "weighted avg       0.81      0.76      0.77      1148\n",
      "\n",
      "Confusion Matrix for Support Vector Machine:\n",
      "[[565 215]\n",
      " [ 58 310]]\n",
      "MCC Score for Support Vector Machine: 0.5309324601109705\n",
      "\n",
      "Fitting Logistic Regression...\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       780\n",
      "           1       0.49      0.76      0.60       368\n",
      "\n",
      "    accuracy                           0.67      1148\n",
      "   macro avg       0.67      0.69      0.66      1148\n",
      "weighted avg       0.73      0.67      0.68      1148\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[489 291]\n",
      " [ 88 280]]\n",
      "MCC Score for Logistic Regression: 0.36196352972599644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply random under-sampling to the training data\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Models to evaluate\n",
    "algorithms = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42)),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "  \n",
    "]\n",
    "\n",
    "for name, model in algorithms:\n",
    "    print(f\"Fitting {name}...\")\n",
    "    # Fit the model to the resampled training data\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Predict anomaly labels on the scaled test data\n",
    "    predicted_labels = model.predict(X_test_scaled)\n",
    "\n",
    "    # Generate a classification report\n",
    "    classification_rep = classification_report(y_test, predicted_labels)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    # Compute the Matthews Correlation Coefficient (MCC) score\n",
    "    mcc = matthews_corrcoef(y_test, predicted_labels)\n",
    "\n",
    "    print(f\"Classification Report for {name}:\\n{classification_rep}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{conf_matrix}\")\n",
    "    print(f\"MCC Score for {name}: {mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bbfe63-8429-426b-abce-00ec444341af",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using RandomsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b3ec6-6e8f-4a2a-b47c-9973f5f130b0",
   "metadata": {},
   "source": [
    "## On Over sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cda02bed-cbc7-440a-bac3-d6c7858281ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForestClassifier: {'n_estimators': 443, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 57, 'bootstrap': True}\n",
      "Best parameters for XGBoostClassifier: {'subsample': 0.8, 'n_estimators': 456, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "Classification Report for the Best RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       780\n",
      "           1       0.83      0.89      0.85       368\n",
      "\n",
      "    accuracy                           0.90      1148\n",
      "   macro avg       0.88      0.90      0.89      1148\n",
      "weighted avg       0.91      0.90      0.90      1148\n",
      "\n",
      "Classification Report for the Best XGBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       780\n",
      "           1       0.92      0.86      0.88       368\n",
      "\n",
      "    accuracy                           0.93      1148\n",
      "   macro avg       0.92      0.91      0.92      1148\n",
      "weighted avg       0.93      0.93      0.93      1148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Random Forest parameter grid\n",
    "rf_param_dist = {\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'max_depth':np.arange(10, 100),\n",
    "    'min_samples_split': np.arange(2, 11),\n",
    "    'min_samples_leaf': np.arange(1, 11),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# XGBoost parameter grid\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100,500),\n",
    "    'max_depth': np.arange(3, 11),\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier and XGBoostClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV for RandomForestClassifier\n",
    "rf_random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=rf_param_dist,\n",
    "                                      n_iter=10, scoring='accuracy', cv=5, random_state=42, n_jobs=-1)\n",
    "rf_random_search.fit(X_train_resampled1, y_train_resampled1)\n",
    "\n",
    "# Initialize RandomizedSearchCV for XGBoostClassifier\n",
    "xgb_random_search = RandomizedSearchCV(estimator=xgb_classifier, param_distributions=xgb_param_dist,\n",
    "                                       n_iter=10, scoring='accuracy', cv=5, random_state=42, n_jobs=-1)\n",
    "xgb_random_search.fit(X_train_resampled1, y_train_resampled1)\n",
    "\n",
    "# Print best parameters for RandomForestClassifier\n",
    "print(\"Best parameters for RandomForestClassifier:\", rf_random_search.best_params_)\n",
    "\n",
    "# Print best parameters for XGBoostClassifier\n",
    "print(\"Best parameters for XGBoostClassifier:\", xgb_random_search.best_params_)\n",
    "\n",
    "# Evaluate the best RandomForestClassifier\n",
    "best_rf_classifier = rf_random_search.best_estimator_\n",
    "predicted_rf = best_rf_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best RandomForestClassifier:\")\n",
    "print(classification_report(y_test, predicted_rf))\n",
    "\n",
    "# Evaluate the best XGBoostClassifier\n",
    "best_xgb_classifier = xgb_random_search.best_estimator_\n",
    "predicted_xgb = best_xgb_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best XGBoostClassifier:\")\n",
    "print(classification_report(y_test, predicted_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00203c46-ae08-4dfb-9e60-e6159326a854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c541b6eb-9427-489e-9e6e-e5851222ae57",
   "metadata": {},
   "source": [
    "## On Under Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a485c6-e4f0-4a09-81de-60ef113b0826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForestClassifier: {'n_estimators': 443, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 57, 'bootstrap': True}\n",
      "Best parameters for XGBoostClassifier: {'subsample': 0.9, 'n_estimators': 395, 'max_depth': 8, 'learning_rate': 0.1, 'colsample_bytree': 0.9}\n",
      "Classification Report for the Best RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       780\n",
      "           1       0.72      0.93      0.82       368\n",
      "\n",
      "    accuracy                           0.86      1148\n",
      "   macro avg       0.84      0.88      0.85      1148\n",
      "weighted avg       0.89      0.86      0.87      1148\n",
      "\n",
      "Classification Report for the Best XGBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       780\n",
      "           1       0.77      0.91      0.84       368\n",
      "\n",
      "    accuracy                           0.89      1148\n",
      "   macro avg       0.86      0.89      0.87      1148\n",
      "weighted avg       0.90      0.89      0.89      1148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Random Forest parameter grid\n",
    "rf_param_dist = {\n",
    "    'n_estimators': np.arange(100, 500),\n",
    "    'max_depth':np.arange(10, 100),\n",
    "    'min_samples_split': np.arange(2, 11),\n",
    "    'min_samples_leaf': np.arange(1, 11),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# XGBoost parameter grid\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100,500),\n",
    "    'max_depth': np.arange(3, 11),\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier and XGBoostClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV for RandomForestClassifier\n",
    "rf_random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=rf_param_dist,\n",
    "                                      n_iter=10, scoring='accuracy', cv=5, random_state=42, n_jobs=-1)\n",
    "rf_random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Initialize RandomizedSearchCV for XGBoostClassifier\n",
    "xgb_random_search = RandomizedSearchCV(estimator=xgb_classifier, param_distributions=xgb_param_dist,\n",
    "                                       n_iter=10, scoring='accuracy', cv=5, random_state=42, n_jobs=-1)\n",
    "xgb_random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print best parameters for RandomForestClassifier\n",
    "print(\"Best parameters for RandomForestClassifier:\", rf_random_search.best_params_)\n",
    "\n",
    "# Print best parameters for XGBoostClassifier\n",
    "print(\"Best parameters for XGBoostClassifier:\", xgb_random_search.best_params_)\n",
    "\n",
    "# Evaluate the best RandomForestClassifier\n",
    "best_rf_classifier = rf_random_search.best_estimator_\n",
    "predicted_rf = best_rf_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best RandomForestClassifier:\")\n",
    "print(classification_report(y_test, predicted_rf))\n",
    "\n",
    "# Evaluate the best XGBoostClassifier\n",
    "best_xgb_classifier = xgb_random_search.best_estimator_\n",
    "predicted_xgb = best_xgb_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best XGBoostClassifier:\")\n",
    "print(classification_report(y_test, predicted_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed684c-b046-4e73-9332-d3a4e945681f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84eec939-9c5c-4c0e-926b-77534a38124d",
   "metadata": {},
   "source": [
    "## Using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89fb2c66-8891-4bed-97af-5a8a8e5e45c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Optimize RandomForestClassifier using Optuna\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_rf\u001b[39m(trial):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Optimize RandomForestClassifier using Optuna\n",
    "def objective_rf(trial):\n",
    "    rf_param_dist = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 11),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 11),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=42, **rf_param_dist)\n",
    "    model.fit(X_train_resampled1, y_train_resampled1)\n",
    "    \n",
    "    predicted_labels = model.predict(X_test_scaled)\n",
    "    accuracy = classification_report(y_test, predicted_labels, output_dict=True)['accuracy']\n",
    "    return accuracy\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50)\n",
    "\n",
    "best_rf_classifier = RandomForestClassifier(random_state=42, **study_rf.best_params)\n",
    "best_rf_classifier.fit(X_train_resampled1, y_train_resampled1)\n",
    "predicted_rf = best_rf_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best RandomForestClassifier:\")\n",
    "print(classification_report(y_test, predicted_rf))\n",
    "\n",
    "# Optimize XGBoostClassifier using Optuna\n",
    "def objective_xgb(trial):\n",
    "    xgb_param_dist = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.1, 0.2, 0.3]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8, 0.9, 1.0]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.8, 0.9, 1.0])\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(random_state=42, **xgb_param_dist)\n",
    "    model.fit(X_train_resampled1, y_train_resampled1)\n",
    "    \n",
    "    predicted_labels = model.predict(X_test_scaled)\n",
    "    accuracy = classification_report(y_test, predicted_labels, output_dict=True)['accuracy']\n",
    "    return accuracy\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "\n",
    "best_xgb_classifier = XGBClassifier(random_state=42, **study_xgb.best_params)\n",
    "best_xgb_classifier.fit(X_train_resampled1, y_train_resampled1)\n",
    "predicted_xgb = best_xgb_classifier.predict(X_test_scaled)\n",
    "print(\"Classification Report for the Best XGBoostClassifier:\")\n",
    "print(classification_report(y_test, predicted_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad748b89-2187-4f48-9f9c-496e92db7b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb9e30b-9089-4ec3-b3b5-32a499e72ac2",
   "metadata": {},
   "source": [
    "## Using RandomForest Looking for the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fd63f8e-42b8-4c4b-bf2b-8a876f9ca075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Create a subset of the data\n",
    "X = log_pandas_df[selected_columns]\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({'Feature': selected_columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1140d-c47e-44d6-a5cc-2e872bd1e2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125c76a7-932d-4c5c-90b8-eb701a814b51",
   "metadata": {},
   "source": [
    "## Again Check Accuraccy Droping feature with less importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "329122f2-2ad1-458c-b2ba-09b0477fed6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest...\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       780\n",
      "           1       0.85      0.90      0.87       368\n",
      "\n",
      "    accuracy                           0.92      1148\n",
      "   macro avg       0.90      0.91      0.90      1148\n",
      "weighted avg       0.92      0.92      0.92      1148\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[721  59]\n",
      " [ 38 330]]\n",
      "MCC Score for Random Forest: 0.8096001347719144\n",
      "\n",
      "Fitting XGBoost...\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       780\n",
      "           1       0.87      0.86      0.86       368\n",
      "\n",
      "    accuracy                           0.91      1148\n",
      "   macro avg       0.90      0.90      0.90      1148\n",
      "weighted avg       0.91      0.91      0.91      1148\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      "[[731  49]\n",
      " [ 53 315]]\n",
      "MCC Score for XGBoost: 0.7954668002357856\n",
      "\n",
      "Fitting Support Vector Machine...\n",
      "Classification Report for Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80       780\n",
      "           1       0.58      0.85      0.69       368\n",
      "\n",
      "    accuracy                           0.75      1148\n",
      "   macro avg       0.74      0.78      0.74      1148\n",
      "weighted avg       0.80      0.75      0.76      1148\n",
      "\n",
      "Confusion Matrix for Support Vector Machine:\n",
      "[[553 227]\n",
      " [ 57 311]]\n",
      "MCC Score for Support Vector Machine: 0.5181911884688502\n",
      "\n",
      "Fitting Logistic Regression...\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       780\n",
      "           1       0.49      0.77      0.60       368\n",
      "\n",
      "    accuracy                           0.67      1148\n",
      "   macro avg       0.67      0.70      0.66      1148\n",
      "weighted avg       0.74      0.67      0.68      1148\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[489 291]\n",
      " [ 84 284]]\n",
      "MCC Score for Logistic Regression: 0.37210460478101093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line',  'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes','date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train1)\n",
    "X_test_scaled = scaler.transform(X_test1)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled2, y_train_resampled2 = smote.fit_resample(X_train_scaled, y_train1)\n",
    "\n",
    "# Models to evaluate\n",
    "algorithms = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42)),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "    # Add other algorithms here\n",
    "]\n",
    "\n",
    "for name, model in algorithms:\n",
    "    print(f\"Fitting {name}...\")\n",
    "    # Fit the model to the resampled training data\n",
    "    model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "    # Predict anomaly labels on the scaled test data\n",
    "    predicted_labels = model.predict(X_test_scaled)\n",
    "\n",
    "    # Generate a classification report\n",
    "    classification_rep = classification_report(y_test1, predicted_labels)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test1, predicted_labels)\n",
    "\n",
    "    # Compute the Matthews Correlation Coefficient (MCC) score\n",
    "    mcc = matthews_corrcoef(y_test1, predicted_labels)\n",
    "\n",
    "    print(f\"Classification Report for {name}:\\n{classification_rep}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{conf_matrix}\")\n",
    "    print(f\"MCC Score for {name}: {mcc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93f456-e49c-46e5-bb1b-ff322a650130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0e47262-edec-4e80-8daa-243896626ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Hyperparameter tuning for Random Forest using Optuna\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrf_objective\u001b[39m(trial):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Hyperparameter tuning for Random Forest using Optuna\n",
    "def rf_objective(trial):\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50,500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
    "    rf_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "    # Predict anomaly labels on the scaled test data\n",
    "    predicted_labels = rf_model.predict(X_test_scaled)\n",
    "\n",
    "    # Compute the Matthews Correlation Coefficient (MCC) score\n",
    "    mcc = matthews_corrcoef(y_test1, predicted_labels)\n",
    "\n",
    "    return mcc\n",
    "\n",
    "rf_study = optuna.create_study(direction='maximize')\n",
    "rf_study.optimize(rf_objective, n_trials=50)\n",
    "\n",
    "best_rf_params = rf_study.best_params\n",
    "print(\"Best Parameters for Random Forest:\", best_rf_params)\n",
    "\n",
    "# Re-fit the best Random Forest model with the optimal parameters\n",
    "best_rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "best_rf_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "# Predict with the best Random Forest model\n",
    "best_rf_predicted_labels = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Generate a classification report for the best Random Forest model\n",
    "best_rf_classification_rep = classification_report(y_test1, best_rf_predicted_labels)\n",
    "\n",
    "# Hyperparameter tuning for XGBoost using Optuna\n",
    "def xgb_objective(trial):\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10)\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(**xgb_params, random_state=42)\n",
    "    xgb_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "    # Predict anomaly labels on the scaled test data\n",
    "    predicted_labels = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "    # Compute the Matthews Correlation Coefficient (MCC) score\n",
    "    mcc = matthews_corrcoef(y_test1, predicted_labels)\n",
    "\n",
    "    return mcc\n",
    "\n",
    "xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(xgb_objective, n_trials=50)\n",
    "\n",
    "best_xgb_params = xgb_study.best_params\n",
    "print(\"Best Parameters for XGBoost:\", best_xgb_params)\n",
    "\n",
    "# Re-fit the best XGBoost model with the optimal parameters\n",
    "best_xgb_model = XGBClassifier(**best_xgb_params, random_state=42)\n",
    "best_xgb_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "# Predict with the best XGBoost model\n",
    "best_xgb_predicted_labels = best_xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Generate a classification report for the best XGBoost model\n",
    "best_xgb_classification_rep = classification_report(y_test1, best_xgb_predicted_labels)\n",
    "\n",
    "# Print the final classification reports\n",
    "print(\"\\nBest Random Forest Model:\")\n",
    "print(f\"Best Random Forest MCC Score: {matthews_corrcoef(y_test1, best_rf_predicted_labels)}\")\n",
    "print(f\"Classification Report for Best Random Forest Model:\\n{best_rf_classification_rep}\")\n",
    "\n",
    "print(\"\\nBest XGBoost Model:\")\n",
    "print(f\"Best XGBoost MCC Score: {matthews_corrcoef(y_test1, best_xgb_predicted_labels)}\")\n",
    "print(f\"Classification Report for Best XGBoost Model:\\n{best_xgb_classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683c57d-6cfc-4211-816e-658700d44edf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, matthews_corrcoef\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m log_pandas_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput12.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Select the columns you want to use for anomaly detection\u001b[39;00m\n\u001b[1;32m     13\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIp_address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP request line\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP status code\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize of the response in bytes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo of Requests\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output12.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('output12.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line', 'user_agent', 'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'response_time', 'year', 'month', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Apply standard scaling\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the pipeline\n",
    "set_config(display='diagram')\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b1a8607-9e48-410e-92a0-26b91dafa9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as random_forest_model.joblib\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       780\n",
      "           1       0.85      0.90      0.87       368\n",
      "\n",
      "    accuracy                           0.92      1148\n",
      "   macro avg       0.90      0.91      0.90      1148\n",
      "weighted avg       0.92      0.92      0.92      1148\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[721  59]\n",
      " [ 38 330]]\n",
      "MCC Score for Random Forest: 0.8096001347719144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line',  'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train1)\n",
    "X_test_scaled = scaler.transform(X_test1)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled2, y_train_resampled2 = smote.fit_resample(X_train_scaled, y_train1)\n",
    "\n",
    "# After training the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "# Save the Random Forest model to a file using joblib\n",
    "model_filename = 'random_forest_model.joblib'\n",
    "joblib.dump(random_forest_model, model_filename)\n",
    "print(f\"Random Forest model saved as {model_filename}\")\n",
    "\n",
    "# Load the Random Forest model from the saved file\n",
    "loaded_random_forest_model = joblib.load(model_filename)\n",
    "\n",
    "# Predict anomaly labels on the scaled test data using the loaded model\n",
    "predicted_labels = loaded_random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test1, predicted_labels)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test1, predicted_labels)\n",
    "\n",
    "# Compute the Matthews Correlation Coefficient (MCC) score\n",
    "mcc = matthews_corrcoef(y_test1, predicted_labels)\n",
    "\n",
    "print(f\"Classification Report for Random Forest:\\n{classification_rep}\")\n",
    "print(f\"Confusion Matrix for Random Forest:\\n{conf_matrix}\")\n",
    "print(f\"MCC Score for Random Forest: {mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d08e499a-594f-4ab6-b959-c97feeb8bbce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as random_forest_model.pkl\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       780\n",
      "           1       0.85      0.90      0.87       368\n",
      "\n",
      "    accuracy                           0.92      1148\n",
      "   macro avg       0.90      0.91      0.90      1148\n",
      "weighted avg       0.92      0.92      0.92      1148\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[721  59]\n",
      " [ 38 330]]\n",
      "MCC Score for Random Forest: 0.8096001347719144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "log_pandas_df = pd.read_csv('Anomaly1.csv')\n",
    "\n",
    "# Select the columns you want to use for anomaly detection\n",
    "selected_columns = ['Ip_address', 'HTTP request line',  'protocol', 'HTTP status code',\n",
    "                    'Size of the response in bytes', 'date', 'hour',\n",
    "                    'minute', 'seconds', 'No of Requests']\n",
    "data_subset = log_pandas_df[selected_columns]\n",
    "\n",
    "# Prepare the target labels\n",
    "y = log_pandas_df['IsAnomaly']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data_subset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train1)\n",
    "X_test_scaled = scaler.transform(X_test1)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled2, y_train_resampled2 = smote.fit_resample(X_train_scaled, y_train1)\n",
    "\n",
    "# After training the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_resampled2, y_train_resampled2)\n",
    "\n",
    "# Save the Random Forest model to a file using pickle\n",
    "model_filename = 'random_forest_model.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(random_forest_model, model_file)\n",
    "\n",
    "print(f\"Random Forest model saved as {model_filename}\")\n",
    "\n",
    "# Load the Random Forest model from the saved file\n",
    "with open(model_filename, 'rb') as model_file:\n",
    "    loaded_random_forest_model = pickle.load(model_file)\n",
    "\n",
    "# Predict anomaly labels on the scaled test data using the loaded model\n",
    "predicted_labels = loaded_random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test1, predicted_labels)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test1, predicted_labels)\n",
    "\n",
    "# Compute the Matthews Correlation Coefficient (MCC) score\n",
    "mcc = matthews_corrcoef(y_test1, predicted_labels)\n",
    "\n",
    "print(f\"Classification Report for Random Forest:\\n{classification_rep}\")\n",
    "print(f\"Confusion Matrix for Random Forest:\\n{conf_matrix}\")\n",
    "print(f\"MCC Score for Random Forest: {mcc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2e3d975-ede2-4d47-bf37-a8d17c63747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f7a295e-3dd9-487f-bb23-412ed1bd9fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpit/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/arpit/anaconda3/lib/python3.10/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=joblib.load(\"random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55cd21f7-d2f6-45b7-884b-75cc12f1db66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (402222965.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    string=\"143.244.50.172 - - [16/Feb/2023:03:28:45 +0530] \"GET /config/getuser?index=0 HTTP/1.1\" 400 248 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0\"\u001b[0m\n\u001b[0m                                                                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "string=\"143.244.50.172 - - [16/Feb/2023:03:28:45 +0530] \"GET /config/getuser?index=0 HTTP/1.1\" 400 248 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0\"\n",
    "l1=[]\n",
    "l1.append(\" \".split(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43474f30-bd68-44d5-929c-88359be3b414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' ']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3625954-8d04-41b8-b463-1e75cc969588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34333567-b3f2-47e6-8665-2f841f22bda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[2415145644,4,6,143,248,16,3,28,45,62]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e469373f-ab35-43a6-aff7-3f60e707a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb3de399-3b4e-4c94-a42b-ce89e39aaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"RandomForestClassifier.pkl\",\"wb\")\n",
    "pickle.dump(RandomForestClassifier, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e30966e-d997-4042-a2fe-667f411278de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e0a3e59-2308-4fb1-ae6b-0d514cf859a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a data sample\n",
    "data = np.array([[2415145644,4,6,143,248,16,3,28,45,62]])\n",
    "\n",
    "# Create a label sample\n",
    "labels = np.array([1])\n",
    "\n",
    "# Create a classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(data, labels)\n",
    "\n",
    "# Predict the class of the first data point\n",
    "prediction = clf.predict(data)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37daca6f-cc8e-426b-be79-1d82d316edf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
